{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball Tracking with OpenCV\n",
    "\n",
    "The goal here is fair self-explanatory:\n",
    "\n",
    "Step #1: Detect the presence of a colored ball using computer vision techniques.   \n",
    "Step #2: Track the ball as it moves around in the video frames, drawing its previous positions as it moves.\n",
    "\n",
    "Original source https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/\n",
    "\n",
    "<img src=\"images/ex-object-tracking.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 65\n",
    "pts = deque(maxlen=buffer)\n",
    "videoFile = \"downloads/videos/ball_tracking_example.mp4\"\n",
    "useVideo = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the tracked points and build a line\n",
    "def drawTrackedPoints(pts):\n",
    "\t# loop over the set of tracked points\n",
    "\tfor i in range(1, len(pts)):\n",
    "\t\t# if either of the tracked points are None, ignore\n",
    "\t\t# them\n",
    "\t\tif pts[i - 1] is None or pts[i] is None:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# otherwise, compute the thickness of the line and\n",
    "\t\t# draw the connecting lines\n",
    "\t\tthickness = int(np.sqrt(buffer / float(i + 1)) * 2.5)\n",
    "\t\tcv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "def buildMaskForCollorRange(frame, lowerCollor = (90, 150, 40), upperCollor = (100, 255, 255)):\n",
    "\t\"\"\"\n",
    "    Create a mask for the object based on the collor range\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : image\n",
    "        image frame\n",
    "    lowerCollor\n",
    "        Lower HSV color space\n",
    "    upperCollor\n",
    "        Upper HSV color space\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    #Blue object in the HSV color space. \tlowerCollor = (90, 150, 40), upperCollor = (100, 255, 255) \n",
    "\n",
    "    #Green object in the HSV color space. lowerCollor = (29, 86, 6),\tupperCollor = (64, 255, 255)\n",
    "    \n",
    "    #Orange object in the HSV color space. lowerCollor = (10, 100, 20), upperCollor = (25, 255, 255)    \n",
    "    \n",
    "    https://stackoverflow.com/questions/10948589/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-withcv\n",
    "\t\"\"\"\n",
    "    \n",
    "    # blur it, and convert it to the HSV\n",
    "\tblurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "\thsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\t# construct a mask for the color \"green\", then perform\n",
    "\t# a series of dilations and erosions to remove any small\n",
    "\t# blobs left in the mask\n",
    "\tmask = cv2.inRange(hsv, lowerCollor, upperCollor)\n",
    "\tmask = cv2.erode(mask, None, iterations=2)\n",
    "\tmask = cv2.dilate(mask, None, iterations=2)\n",
    "\treturn mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a video path was not supplied, grab the reference to the webcam\n",
    "if not useVideo:\n",
    "\tvs = VideoStream(src=0).start()\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(videoFile)\n",
    "\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    "\t# grab the current frame\n",
    "\tframe = vs.read()\n",
    "\n",
    "\t# handle the frame from VideoCapture or VideoStream\n",
    "\tframe = frame[1] if useVideo else frame\n",
    "\n",
    "\t# if we are viewing a video and we did not grab a frame,\n",
    "\t# then we have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "        \n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\tmask = buildMaskForCollorRange(frame)\n",
    "\t\n",
    "\t# find contours in the mask and initialize the current\n",
    "\t# (x, y) center of the ball\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tcenter = None\n",
    "\n",
    "\t# only proceed if at least one contour was found\n",
    "\tif len(cnts) > 0:\n",
    "\t\t# find the largest contour in the mask, then use\n",
    "\t\t# it to compute the minimum enclosing circle and\n",
    "\t\t# centroid\n",
    "\t\tc = max(cnts, key=cv2.contourArea)\n",
    "\t\t((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\t\tM = cv2.moments(c)\n",
    "\t\tcenter = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "\t\t# only proceed if the radius meets a minimum size\n",
    "\t\tif radius > 10:\n",
    "\t\t\t# draw the circle and centroid on the frame,\n",
    "\t\t\t# then update the list of tracked points\n",
    "\t\t\tcv2.circle(frame, (int(x), int(y)), int(radius),(0, 255, 255), 2)\n",
    "\t\t\tcv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "\t# update the points queue\n",
    "\tpts.appendleft(center)\n",
    "\tdrawTrackedPoints(pts)\n",
    "    \n",
    "\t# show the frame to our screen\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the 'q' key is pressed, stop the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "if not useVideo:\n",
    "\tvs.stop()\n",
    "\n",
    "# otherwise, release the camera\n",
    "else:\n",
    "\tvs.release()\n",
    "\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
