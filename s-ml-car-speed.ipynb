{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Vehicle Detection, Tracking, and Speed Estimation\n",
    "\n",
    "\n",
    "![alt text](https://pyimagesearch.com/wp-content/uploads/2019/12/neighborhood_speed_physics_not_cal.jpg \"Speed estimation\")\n",
    "\n",
    "\n",
    "\n",
    "https://www.pyimagesearch.com/2019/12/02/opencv-vehicle-detection-tracking-and-speed-estimation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] NOTE: When using an input video file, speeds will be inaccurate because OpenCV can't throttle FPS according to the framerate of the video. This script is for development purposes only.\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# NOTE: When using an input video file, speeds will be inaccurate\n",
    "# because OpenCV can't throttle FPS according to the framerate of the\n",
    "# video. This script is for development purposes only.\n",
    "\n",
    "# inform the user about framerates and speeds\n",
    "print(\"[INFO] NOTE: When using an input video file, speeds will be \" \\\n",
    "      \"inaccurate because OpenCV can't throttle FPS according to the \" \\\n",
    "      \"framerate of the video. This script is for development purposes \" \\\n",
    "      \"only.\")\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.centroidtracker import CentroidTracker\n",
    "from pyimagesearch.trackableobject import TrackableObject\n",
    "from pyimagesearch.utils import Conf\n",
    "from imutils.video import VideoStream\n",
    "from imutils.io import TempFile\n",
    "from imutils.video import FPS\n",
    "from datetime import datetime\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "args ={}\n",
    "args[\"input\"] = \"downloads/videos/speed-cars.mp4\"\n",
    "args[\"conf\"] = \"downloads/models-cia/car-speed-config.json\"\n",
    "args[\"prototxt_path\"] = \"downloads/models-cia/MobileNetSSD_deploy.prototxt\"\n",
    "args[\"model_path\"] = \"downloads/models-cia/MobileNetSSD_deploy.caffemodel\"\n",
    "args[\"use_video\"] =1\n",
    "\n",
    "# load the configuration file\n",
    "conf = Conf(args[\"conf\"])\n",
    "\n",
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt_path\"], args[\"model_path\"])\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_MYRIAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] warming up camera...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and allow the camera sensor to warmup\n",
    "print(\"[INFO] warming up camera...\")\n",
    "if args[\"use_video\"]:\n",
    "\tvs = cv2.VideoCapture(args[\"input\"])    \n",
    "else:\n",
    "\tvs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# initialize the frame dimensions (we'll set them as soon as we read\n",
    "# the first frame from the video)\n",
    "H = None\n",
    "W = None\n",
    "\n",
    "# instantiate our centroid tracker, then initialize a list to store\n",
    "# each of our dlib correlation trackers, followed by a dictionary to\n",
    "# map each unique object ID to a TrackableObject\n",
    "ct = CentroidTracker(maxDisappeared=conf[\"max_disappear\"], maxDistance=conf[\"max_distance\"])\n",
    "trackers = []\n",
    "trackableObjects = {}\n",
    "\n",
    "# keep the count of total number of frames\n",
    "totalFrames = 0\n",
    "\n",
    "# initialize the list of various points used to calculate the avg of\n",
    "# the vehicle speed\n",
    "points = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\")]\n",
    "\n",
    "# start the frames per second throughput estimator\n",
    "fps = FPS().start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Speed of the vehicle that just passed is: 46.96 MPH\n",
      "[INFO] vehicle over the speed limit 2020,05,31,12:00:16,46.96220303381363\n",
      "\n",
      "[INFO] Speed of the vehicle that just passed is: 34.78 MPH\n",
      "[INFO] vehicle over the speed limit 2020,05,31,12:00:19,34.77830103587349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop over the frames of the stream\n",
    "while True:\n",
    "\t# grab the next frame from the stream, store the current\n",
    "\t# timestamp, and store the new date\n",
    "\tif args[\"use_video\"]:\n",
    "\t\tret, frame = vs.read()\n",
    "\telse:\n",
    "\t\tframe = vs.read()\n",
    "        \n",
    "\tts = datetime.now()\n",
    "\tnewDate = ts.strftime(\"%m-%d-%y\")\n",
    "\n",
    "\t# check if the frame is None, if so, break out of the loop\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the frame\n",
    "\tframe = imutils.resize(frame, width=conf[\"frame_width\"])\n",
    "\trgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t# if the frame dimensions are empty, set them\n",
    "\tif W is None or H is None:\n",
    "\t\t(H, W) = frame.shape[:2]\n",
    "\t\tmeterPerPixel = conf[\"distance\"] / W\n",
    "\n",
    "\t# initialize our list of bounding box rectangles returned by\n",
    "\t# either (1) our object detector or (2) the correlation trackers\n",
    "\trects = []\n",
    "\n",
    "\t# check to see if we should run a more computationally expensive\n",
    "\t# object detection method to aid our tracker\n",
    "\tif totalFrames % conf[\"track_object\"] == 0:\n",
    "\t\t# initialize our new set of object trackers\n",
    "\t\ttrackers = []\n",
    "\n",
    "\t\t# convert the frame to a blob and pass the blob through the\n",
    "\t\t# network and obtain the detections\n",
    "\t\tblob = cv2.dnn.blobFromImage(frame, size=(300, 300), ddepth=cv2.CV_8U)\n",
    "\t\tnet.setInput(blob, scalefactor=1.0/127.5, mean=[127.5, 127.5, 127.5])\n",
    "\t\tdetections = net.forward()\n",
    "\n",
    "\t\t# loop over the detections\n",
    "\t\tfor i in np.arange(0, detections.shape[2]):\n",
    "\t\t\t# extract the confidence (i.e., probability) associated\n",
    "\t\t\t# with the prediction\n",
    "\t\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t\t# filter out weak detections by ensuring the `confidence`\n",
    "\t\t\t# is greater than the minimum confidence\n",
    "\t\t\tif confidence > conf[\"confidence\"]:\n",
    "\t\t\t\t# extract the index of the class label from the\n",
    "\t\t\t\t# detections list\n",
    "\t\t\t\tidx = int(detections[0, 0, i, 1])\n",
    "\n",
    "\t\t\t\t# if the class label is not a car, ignore it\n",
    "\t\t\t\tif CLASSES[idx] != \"car\":\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# compute the (x, y)-coordinates of the bounding box\n",
    "\t\t\t\t# for the object\n",
    "\t\t\t\tbox = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "\t\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t\t# construct a dlib rectangle object from the bounding\n",
    "\t\t\t\t# box coordinates and then start the dlib correlation\n",
    "\t\t\t\t# tracker\n",
    "\t\t\t\ttracker = dlib.correlation_tracker()\n",
    "\t\t\t\trect = dlib.rectangle(startX, startY, endX, endY)\n",
    "\t\t\t\ttracker.start_track(rgb, rect)\n",
    "\n",
    "\t\t\t\t# add the tracker to our list of trackers so we can\n",
    "\t\t\t\t# utilize it during skip frames\n",
    "\t\t\t\ttrackers.append(tracker)\n",
    "\n",
    "\t# otherwise, we should utilize our object *trackers* rather than\n",
    "\t# object *detectors* to obtain a higher frame processing\n",
    "\t# throughput\n",
    "\telse:\n",
    "\t\t# loop over the trackers\n",
    "\t\tfor tracker in trackers:\n",
    "\t\t\t# update the tracker and grab the updated position\n",
    "\t\t\ttracker.update(rgb)\n",
    "\t\t\tpos = tracker.get_position()\n",
    "\n",
    "\t\t\t# unpack the position object\n",
    "\t\t\tstartX = int(pos.left())\n",
    "\t\t\tstartY = int(pos.top())\n",
    "\t\t\tendX = int(pos.right())\n",
    "\t\t\tendY = int(pos.bottom())\n",
    "\n",
    "\t\t\t# add the bounding box coordinates to the rectangles list\n",
    "\t\t\trects.append((startX, startY, endX, endY))\n",
    "\n",
    "\t# use the centroid tracker to associate the (1) old object\n",
    "\t# centroids with (2) the newly computed object centroids\n",
    "\tobjects = ct.update(rects)\n",
    "\n",
    "\t# loop over the tracked objects\n",
    "\tfor (objectID, centroid) in objects.items():\n",
    "\t\t# check to see if a trackable object exists for the current\n",
    "\t\t# object ID\n",
    "\t\tto = trackableObjects.get(objectID, None)\n",
    "\n",
    "\t\t# if there is no existing trackable object, create one\n",
    "\t\tif to is None:\n",
    "\t\t\tto = TrackableObject(objectID, centroid)\n",
    "\n",
    "\t\t# otherwise, if there is a trackable object and its speed has\n",
    "\t\t# not yet been estimated then estimate it\n",
    "\t\telif not to.estimated:\n",
    "\t\t\t# check if the direction of the object has been set, if\n",
    "\t\t\t# not, calculate it, and set it\n",
    "\t\t\tif to.direction is None:\n",
    "\t\t\t\ty = [c[0] for c in to.centroids]\n",
    "\t\t\t\tdirection = centroid[0] - np.mean(y)\n",
    "\t\t\t\tto.direction = direction\n",
    "\n",
    "\t\t\t# if the direction is positive (indicating the object\n",
    "\t\t\t# is moving from left to right)\n",
    "\t\t\tif to.direction > 0:\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point A\n",
    "\t\t\t\tif to.timestamp[\"A\"] == 0 :\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is greater than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] > conf[\"speed_estimation_zone\"][\"A\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"A\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"A\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point B\n",
    "\t\t\t\telif to.timestamp[\"B\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is greater than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] > conf[\"speed_estimation_zone\"][\"B\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"B\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"B\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point C\n",
    "\t\t\t\telif to.timestamp[\"C\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is greater than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] > conf[\"speed_estimation_zone\"][\"C\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"C\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"C\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point D\n",
    "\t\t\t\telif to.timestamp[\"D\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is greater than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp, set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate, and set the last point\n",
    "\t\t\t\t\t# flag as True\n",
    "\t\t\t\t\tif centroid[0] > conf[\"speed_estimation_zone\"][\"D\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"D\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"D\"] = centroid[0]\n",
    "\t\t\t\t\t\tto.lastPoint = True\n",
    "\n",
    "\t\t\t# if the direction is negative (indicating the object\n",
    "\t\t\t# is moving from right to left)\n",
    "\t\t\telif to.direction < 0:\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point D\n",
    "\t\t\t\tif to.timestamp[\"D\"] == 0 :\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is lesser than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] < conf[\"speed_estimation_zone\"][\"D\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"D\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"D\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point C\n",
    "\t\t\t\telif to.timestamp[\"C\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is lesser than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] < conf[\"speed_estimation_zone\"][\"C\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"C\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"C\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point B\n",
    "\t\t\t\telif to.timestamp[\"B\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is lesser than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp and set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate\n",
    "\t\t\t\t\tif centroid[0] < conf[\"speed_estimation_zone\"][\"B\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"B\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"B\"] = centroid[0]\n",
    "\n",
    "\t\t\t\t# check to see if timestamp has been noted for\n",
    "\t\t\t\t# point A\n",
    "\t\t\t\telif to.timestamp[\"A\"] == 0:\n",
    "\t\t\t\t\t# if the centroid's x-coordinate is lesser than\n",
    "\t\t\t\t\t# the corresponding point then set the timestamp\n",
    "\t\t\t\t\t# as current timestamp, set the position as the\n",
    "\t\t\t\t\t# centroid's x-coordinate, and set the last point\n",
    "\t\t\t\t\t# flag as True\n",
    "\t\t\t\t\tif centroid[0] < conf[\"speed_estimation_zone\"][\"A\"]:\n",
    "\t\t\t\t\t\tto.timestamp[\"A\"] = ts\n",
    "\t\t\t\t\t\tto.position[\"A\"] = centroid[0]\n",
    "\t\t\t\t\t\tto.lastPoint = True\n",
    "\n",
    "\t\t\t# check to see if the vehicle is past the last point and\n",
    "\t\t\t# the vehicle's speed has not yet been estimated, if yes,\n",
    "\t\t\t# then calculate the vehicle speed and log it if it's\n",
    "\t\t\t# over the limit\n",
    "\t\t\tif to.lastPoint and not to.estimated:\n",
    "\t\t\t\t# initialize the list of estimated speeds\n",
    "\t\t\t\testimatedSpeeds = []\n",
    "\n",
    "\t\t\t\t# loop over all the pairs of points and estimate the\n",
    "\t\t\t\t# vehicle speed\n",
    "\t\t\t\tfor (i, j) in points:\n",
    "\t\t\t\t\t# calculate the distance in pixels\n",
    "\t\t\t\t\td = to.position[j] - to.position[i]\n",
    "\t\t\t\t\tdistanceInPixels = abs(d)\n",
    "\n",
    "\t\t\t\t\t# check if the distance in pixels is zero, if so,\n",
    "\t\t\t\t\t# skip this iteration\n",
    "\t\t\t\t\tif distanceInPixels == 0:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\t# calculate the time in hours\n",
    "\t\t\t\t\tt = to.timestamp[j] - to.timestamp[i]\n",
    "\t\t\t\t\ttimeInSeconds = abs(t.total_seconds())\n",
    "\t\t\t\t\ttimeInHours = timeInSeconds / (60 * 60)\n",
    "\n",
    "\t\t\t\t\t# calculate distance in kilometers and append the\n",
    "\t\t\t\t\t# calculated speed to the list\n",
    "\t\t\t\t\tdistanceInMeters = distanceInPixels * meterPerPixel\n",
    "\t\t\t\t\tdistanceInKM = distanceInMeters / 1000\n",
    "\t\t\t\t\testimatedSpeeds.append(distanceInKM / timeInHours)\n",
    "\n",
    "\t\t\t\t# calculate the average speed\n",
    "\t\t\t\tto.calculate_speed(estimatedSpeeds)\n",
    "\n",
    "\t\t\t\t# set the object as estimated\n",
    "\t\t\t\tto.estimated = True\n",
    "\t\t\t\tprint(\"[INFO] Speed of the vehicle that just passed is: {:.2f} MPH\".format(to.speedMPH))\n",
    "\n",
    "\t\t# store the trackable object in our dictionary\n",
    "\t\ttrackableObjects[objectID] = to\n",
    "\n",
    "\t\t# draw both the ID of the object and the centroid of the\n",
    "\t\t# object on the output frame\n",
    "\t\ttext = \"ID {}\".format(objectID)\n",
    "\t\tcv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10) , cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\t\tcv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "\n",
    "\t\t# check if the object has not been logged\n",
    "\t\tif not to.logged:\n",
    "\t\t\t# check if the object's speed has been estimated and it\n",
    "\t\t\t# is higher than the speed limit\n",
    "\t\t\tif to.estimated and to.speedMPH > conf[\"speed_limit\"]:\n",
    "\t\t\t\t# set the current year, month, day, and time\n",
    "\t\t\t\tyear = ts.strftime(\"%Y\")\n",
    "\t\t\t\tmonth = ts.strftime(\"%m\")\n",
    "\t\t\t\tday = ts.strftime(\"%d\")\n",
    "\t\t\t\ttime = ts.strftime(\"%H:%M:%S\")\n",
    "\n",
    "\t\t\t\t# log the event in the log file\n",
    "\t\t\t\tinfo = \"{},{},{},{},{}\\n\".format(year, month,day, time, to.speedMPH)\n",
    "\t\t\t\tprint(\"[INFO] vehicle over the speed limit \" + info )\n",
    "\t\t\t\t# set the object has logged\n",
    "\t\t\t\tto.logged = True\n",
    "\n",
    "\t# if the *display* flag is set, then display the current frame\n",
    "\t# to the screen and record if a user presses a key\n",
    "\tif conf[\"display\"]:\n",
    "\t\tcv2.imshow(\"frame\", frame)\n",
    "\t\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t\t# if the `q` key is pressed, break from the loop\n",
    "\t\tif key == ord(\"q\"):\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# increment the total number of frames processed thus far and\n",
    "\t# then update the FPS counter\n",
    "\ttotalFrames += 1\n",
    "\tfps.update()\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# check if the log file object exists, if it does, then close it\n",
    "if logFile is not None:\n",
    "\tlogFile.close()\n",
    "\n",
    "# close any open windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# clean up\n",
    "print(\"[INFO] cleaning up...\")\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
